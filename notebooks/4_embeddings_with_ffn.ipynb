{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a215be2",
   "metadata": {},
   "source": [
    "# Обучение головы (FFN) на эмбеддингах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e4476",
   "metadata": {},
   "source": [
    "Если запускаете, полностью клонировав репозиторий локально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd674a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710c146",
   "metadata": {},
   "source": [
    "Если используете блокнот независимо от проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade git+https://github.com/rimgro/biocadprotein.git\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1715a",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9f40a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "from fpgen.prop_prediction.dataset import FPbase\n",
    "from fpgen.prop_prediction.metrics import (\n",
    "    get_regression_metrics,\n",
    "    get_classification_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c53515",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e515b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(line):\n",
    "    clean_line = line.replace('\\n', ' ').strip('[]')\n",
    "    numbers = np.fromstring(clean_line, sep=' ')\n",
    "\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b28af7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>brightness</th>\n",
       "      <th>em_max</th>\n",
       "      <th>ex_max</th>\n",
       "      <th>ext_coeff</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>maturation</th>\n",
       "      <th>pka</th>\n",
       "      <th>stokes_shift</th>\n",
       "      <th>qy</th>\n",
       "      <th>agg</th>\n",
       "      <th>switch_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[-0.00530367903, 0.00854283385, 0.00128412445,...</td>\n",
       "      <td>-0.516789</td>\n",
       "      <td>-1.357357</td>\n",
       "      <td>-1.875798</td>\n",
       "      <td>-0.814071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.923046</td>\n",
       "      <td>-0.056729</td>\n",
       "      <td>m</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[-0.00167965586, 0.00413581124, 0.00335621182,...</td>\n",
       "      <td>-0.802832</td>\n",
       "      <td>-0.408006</td>\n",
       "      <td>-0.214689</td>\n",
       "      <td>-1.192834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.878962</td>\n",
       "      <td>-0.403015</td>\n",
       "      <td>-0.465539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>[-0.00447917636, -0.00560046919, 0.00733367307...</td>\n",
       "      <td>-1.040228</td>\n",
       "      <td>0.883734</td>\n",
       "      <td>0.758032</td>\n",
       "      <td>-0.257845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074367</td>\n",
       "      <td>-1.725418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>[-0.00244280021, 0.0043460303, 0.00649108412, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.516948</td>\n",
       "      <td>-0.184759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.641706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[-0.00111842179, -0.00419556629, 0.00596778374...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.610327</td>\n",
       "      <td>-0.244619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sequence  brightness    em_max  \\\n",
       "558  [-0.00530367903, 0.00854283385, 0.00128412445,...   -0.516789 -1.357357   \n",
       "149  [-0.00167965586, 0.00413581124, 0.00335621182,...   -0.802832 -0.408006   \n",
       "184  [-0.00447917636, -0.00560046919, 0.00733367307...   -1.040228  0.883734   \n",
       "291  [-0.00244280021, 0.0043460303, 0.00649108412, ...         NaN -0.516948   \n",
       "30   [-0.00111842179, -0.00419556629, 0.00596778374...         NaN -0.610327   \n",
       "\n",
       "       ex_max  ext_coeff  lifetime  maturation       pka  stokes_shift  \\\n",
       "558 -1.875798  -0.814071       NaN         NaN  0.323540      0.923046   \n",
       "149 -0.214689  -1.192834       NaN         NaN  1.878962     -0.403015   \n",
       "184  0.758032  -0.257845       NaN         NaN       NaN      0.074367   \n",
       "291 -0.184759        NaN       NaN         NaN       NaN     -0.641706   \n",
       "30  -0.244619        NaN       NaN         NaN       NaN     -0.694749   \n",
       "\n",
       "           qy  agg switch_type  \n",
       "558 -0.056729    m           b  \n",
       "149 -0.465539  NaN           b  \n",
       "184 -1.725418  NaN           b  \n",
       "291       NaN    m           b  \n",
       "30        NaN    t           b  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = FPbase('../data/dataset_embedd.csv', preprocess_function=preproc)\n",
    "dataset.to_train_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef8b5d",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58a04ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'ex_max'\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_FOLDS = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "983bf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_size = input_size\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(last_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            last_size = hidden_size\n",
    "            \n",
    "        layers.append(nn.Linear(last_size, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea709636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/4 ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[2, 5, 16, 37, 40, 42, 46, 47, 69, 87, 92, 94, 107, 109, 114, 117, 128, 133, 136, 143, 144, 145, 155, 158, 167, 168, 172, 175, 179, 181, 191, 193, 208, 212, 220, 230, 232, 234, 241, 242, 243, 248, 249, 250, 251, 254, 255, 257, 260, 262, 270, 274, 278, 283, 285, 288, 289, 304, 316, 320, 338, 340, 352, 358, 359, 361, 389, 395, 403, 405, 406, 409, 411, 418, 419, 433, 436, 445, 455, 456, 466, 470, 471, 472, 475, 476, 482, 483, 485, 486, 488, 489, 491, 492, 500, 502, 503, 504, 506, 507, 510, 512, 514, 520, 523, 528, 536, 546, 553, 556, 557, 561, 572, 577, 583, 588, 590, 593, 594, 596, 601, 603, 609, 616, 624, 625, 630, 635, 642, 648, 657, 668, 669, 673, 674] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_FOLDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Подготовка данных\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X_train, y_train = \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m, y[train_idx]\n\u001b[32m     14\u001b[39m X_val, y_val = X[val_idx], y[val_idx]\n\u001b[32m     16\u001b[39m train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n\u001b[32m     17\u001b[39m                               torch.tensor(y_train, dtype=torch.float32))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1162\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1159\u001b[39m     key = np.asarray(key, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m   1160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_rows_with_mask(key)\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1189\u001b[39m, in \u001b[36mSeries._get_with\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key_type == \u001b[33m\"\u001b[39m\u001b[33minteger\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[32m   1187\u001b[39m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[32m   1188\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.index._should_fallback_to_positional:\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1190\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1191\u001b[39m         warnings.warn(\n\u001b[32m   1192\u001b[39m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[32m   1193\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1198\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m   1199\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1359\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1362\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1363\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1555\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1556\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: '[2, 5, 16, 37, 40, 42, 46, 47, 69, 87, 92, 94, 107, 109, 114, 117, 128, 133, 136, 143, 144, 145, 155, 158, 167, 168, 172, 175, 179, 181, 191, 193, 208, 212, 220, 230, 232, 234, 241, 242, 243, 248, 249, 250, 251, 254, 255, 257, 260, 262, 270, 274, 278, 283, 285, 288, 289, 304, 316, 320, 338, 340, 352, 358, 359, 361, 389, 395, 403, 405, 406, 409, 411, 418, 419, 433, 436, 445, 455, 456, 466, 470, 471, 472, 475, 476, 482, 483, 485, 486, 488, 489, 491, 492, 500, 502, 503, 504, 506, 507, 510, 512, 514, 520, 523, 528, 536, 546, 553, 556, 557, 561, 572, 577, 583, 588, 590, 593, 594, 596, 601, 603, 609, 616, 624, 625, 630, 635, 642, 648, 657, 668, 669, 673, 674] not in index'"
     ]
    }
   ],
   "source": [
    "X, y_series = dataset.get_train(TARGET, is_scaled=True)\n",
    "\n",
    "y = y_series.values.reshape(-1, 1)\n",
    "\n",
    "# --- Кросс-валидация ---\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=52)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{NUM_FOLDS} ---\")\n",
    "\n",
    "    # Подготовка данных\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                  torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                torch.tensor(y_val, dtype=torch.float32))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Модель, оптимизатор, лосс\n",
    "    model = FNNRegressor(input_dim=X.shape[1]).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1:3d} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Оценка\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            pred = model(xb).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            targets.append(yb.numpy())\n",
    "    preds = np.vstack(preds).flatten()\n",
    "    targets = np.vstack(targets).flatten()\n",
    "\n",
    "    # Метрики\n",
    "    metrics = get_regression_metrics(y_pred=preds, y_true=targets)\n",
    "    all_metrics.append(metrics)\n",
    "    print(f\"Fold {fold+1} Metrics: {metrics}\")\n",
    "\n",
    "# --- Средние метрики по фолдам ---\n",
    "print(\"\\n=== Average Metrics ===\")\n",
    "avg_metrics = {\n",
    "    k: np.mean([m[k] for m in all_metrics])\n",
    "    for k in all_metrics[0]\n",
    "}\n",
    "for name, value in avg_metrics.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7612654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
